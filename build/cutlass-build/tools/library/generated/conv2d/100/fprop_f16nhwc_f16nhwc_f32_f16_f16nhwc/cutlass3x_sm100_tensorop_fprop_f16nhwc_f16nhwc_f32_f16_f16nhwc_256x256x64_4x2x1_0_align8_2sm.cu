
/*
  Generated by conv2d_operation.py - Do not edit.
*/

///////////////////////////////////////////////////////////////////////////////////////////////////

#include "cutlass/cutlass.h"
#include "cutlass/library/library.h"
#include "cutlass/library/manifest.h"

#include "library_internal.h"
#include "conv_operation_3x.hpp"
#include "cutlass/conv/device/conv_universal_adapter.hpp"
#include "cutlass/conv/kernel/conv_universal.hpp"
#include "cutlass/conv/collective/collective_builder.hpp"
#include "cutlass/epilogue/collective/collective_builder.hpp"

///////////////////////////////////////////////////////////////////////////////////////////////////



// CUTLASS >= 3 convolution Fprop kernel instance "cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm"
using cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_epilogue =
  typename cutlass::epilogue::collective::CollectiveBuilder<
    cutlass::arch::Sm100,
    cutlass::arch::OpClassTensorOp,
    cute::Shape<cute::_128, cute::_128, cute::Shape<cute::_64>>,               // mma tile shape
    cute::Shape<cute::_4, cute::_2, cute::_1>,                // cluster shape
    cutlass::epilogue::collective::EpilogueTileAuto,
    float,
    float,
    cutlass::half_t, cutlass::layout::TensorNHWC, 128 / cute::sizeof_bits_v<cutlass::half_t>,
    cutlass::half_t, cutlass::layout::TensorNHWC, 128 / cute::sizeof_bits_v<cutlass::half_t>,
    cutlass::epilogue::collective::EpilogueScheduleAuto
    // , class FusionOpOrCallbacks = cutlass::epilogue::fusion::LinearCombination<ElementD,ElementCompute>
  >::CollectiveOp;

using cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_mainloop =
  typename cutlass::conv::collective::CollectiveBuilder<
    cutlass::arch::Sm100,
    cutlass::arch::OpClassTensorOp,
    cutlass::conv::Operator::kFprop,         // kFprop, kDgrad, or kWgrad
    cutlass::half_t, cutlass::layout::TensorNHWC, 128 / cute::sizeof_bits_v<cutlass::half_t>,
    cutlass::half_t, cutlass::layout::TensorNHWC, 128 / cute::sizeof_bits_v<cutlass::half_t>,
    float,
    cute::Shape<cute::_128, cute::_128, cute::Shape<cute::_64>>,        // mma tile shape
    cute::Shape<cute::_4, cute::_2, cute::_1>,         // cluster shape
    cutlass::conv::collective::StageCountAutoCarveout<sizeof(typename cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_epilogue::SharedStorage)>,
    cutlass::conv::KernelImplicitTmaWarpSpecialized2SmSm100
  >::CollectiveOp;

using cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_problem_shape = cutlass::conv::ConvProblemShape<cutlass::conv::Operator::kFprop, cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_mainloop::NumSpatialDimensions>;

// Unit tests call this "ConvKernel".
// Conv operator cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm
using cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_base = cutlass::conv::kernel::ConvUniversal<
    cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_problem_shape,
    cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_mainloop,
    cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_epilogue,
    void
  >;

// Derived class
struct cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm :
  public cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm_base { };

///////////////////////////////////////////////////////////////////////////////////////////////////



namespace cutlass {
namespace library {

// Initialize all instances
void initialize_cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm(Manifest &manifest) {

  using Operation_cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm = cutlass::conv::device::ConvUniversalAdapter<
    cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm>;

  manifest.append(new cutlass::library::ConvOperation3x<
      Operation_cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm
    >(
      "cutlass3x_sm100_tensorop_fprop_f16nhwc_f16nhwc_f32_f16_f16nhwc_256x256x64_4x2x1_0_align8_2sm"
    ));

}


///////////////////////////////////////////////////////////////////////////////////////////////////

} // namespace library
} // namespace cutlass

///////////////////////////////////////////////////////////////////////////////////////////////////

